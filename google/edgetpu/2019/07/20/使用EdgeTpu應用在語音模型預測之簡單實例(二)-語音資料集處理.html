<!DOCTYPE html>
<html>







<head>
  <meta charset="utf-8">
  <title>
    JYU Blog - 使用EdgeTpu應用在語音模型預測之簡單實例(二)-語音資料集處理
  </title>
  <!-- JS -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.8/dist/umd/popper.min.js"
    integrity="sha384-I7E8VVD/ismYTF4hNIPjVp/Zjvgyol6VFvRkX/vR+Vc4jQkC+hVqc2pM8ODewa9r"
    crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/js/bootstrap.min.js"
    integrity="sha384-Rx+T1VzGupg4BHQYs2gCW9It+akI2MM/mndMCy36UVfodzcJcF0GGLxZIzObiEfa"
    crossorigin="anonymous"></script>

  <script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/pace-js@latest/pace.min.js"></script>

  <!-- 針對是否為Production Mode對應特定Js套件來源引入 -->
  <!-- 

  <script src="https://cdnjs.cloudflare.com/ajax/libs/vue/3.2.29/vue.global.prod.min.js"
    integrity="sha512-NZwTAzVi1EAKCNv0XBX0j3+4UyjSlMjYSrfZw9l8Vi+oSCMUWhnadIBcqbODVuird9fAsl5fx6ysQT2lGxsQjw=="
    crossorigin="anonymous" referrerpolicy="no-referrer"></script>

   -->

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/MainStyles.css" />
  
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-4bw+/aepP/YC94hEpVNVgiZdgIC5+VKNBQNGCHeKRQN+PtmoHDEXuppvnDJzQIu9" crossorigin="anonymous">

  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.4/css/all.css"
    integrity="sha384-DyZ88mC6Up2uqS4h/KRgHuoeGwBcD4Ng9SiP4dIRy0EXTlnuz47vAwmeGwVChigm" crossorigin="anonymous">
  <link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pace-js@latest/pace-theme-default.min.css">
</head>







<body>
  






<div class="container">
    <header
        class="d-flex flex-wrap align-items-center justify-content-center justify-content-md-between py-3 mb-4 border-bottom">

        <div class="col-md-3 text-start fs-3">
            JYU Blog
        </div>

        <ul class="nav nav-pills col-12 col-md-auto mb-2 fs-5 justify-content-center mb-md-0">
            <li class="nav-item">
                <a class="nav-link text-body" href="/" class="nav-link px-2 link-secondary">Home</a>
            </li>
            <li class="nav-item">
                <a class="nav-link text-body" href="/about" class="nav-link px-2 link-secondary">About</a>
            </li>
        </ul>

        <div class="col-md-3 text-end">
        </div>

    </header>
</div>
  






<main class="container-sm">
    <nav style="--bs-breadcrumb-divider: url(&#34;data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='8' height='8'%3E%3Cpath d='M2.5 0L1 1.5 3.5 4 1 6.5 2.5 8l4-4-4-4z' fill='currentColor'/%3E%3C/svg%3E&#34;);"
        aria-label="breadcrumb">
        <ol class="breadcrumb">
            <li class="breadcrumb-item"><i class="fas fa-home"></i> <a href="/">Home</a></li>
            <li class="breadcrumb-item active" aria-current="page">使用EdgeTpu應用在語音模型預測之簡單實例(二)-語音資料集處理</li>
        </ol>
    </nav>
    <hr />
</main>

  <main class="container-sm">

    <div class="mb-3">
      <span class="fs-3" style="color: #A6341B;">使用EdgeTpu應用在語音模型預測之簡單實例(二)-語音資料集處理</span>
      <br />
      <span class="fs-6 opacity-75 text-secondary">
        <i class="fas fa-clock text-info"></i>
        2019-07-20 16:00:00
      </span>
    </div>

    <!--more-->

<p>GitHub：<a href="https://github.com/s123600g/asr_edgetpu_demo">https://github.com/s123600g/asr_edgetpu_demo</a></p>

<p>關於環境配置部分請參考 <a href="https://s123600g.github.io/google/edgetpu/2019/07/20/%E4%BD%BF%E7%94%A8EdgeTpu%E6%87%89%E7%94%A8%E5%9C%A8%E8%AA%9E%E9%9F%B3%E6%A8%A1%E5%9E%8B%E9%A0%90%E6%B8%AC%E4%B9%8B%E7%B0%A1%E5%96%AE%E5%AF%A6%E4%BE%8B(%E4%B8%80)-%E5%89%8D%E8%A8%80%E8%88%87%E9%96%8B%E7%99%BC%E7%92%B0%E5%A2%83%E9%85%8D%E7%BD%AE.html">(一)前言與開發環境配置</a></p>

<p>在此階段我們要將語音檔案擷取出語音特徵，並且產生下一階段<a href="https://s123600g.github.io/google/edgetpu/2019/07/20/%E4%BD%BF%E7%94%A8EdgeTpu%E6%87%89%E7%94%A8%E5%9C%A8%E8%AA%9E%E9%9F%B3%E6%A8%A1%E5%9E%8B%E9%A0%90%E6%B8%AC%E4%B9%8B%E7%B0%A1%E5%96%AE%E5%AF%A6%E4%BE%8B(%E4%B8%89)-%E5%BB%BA%E7%AB%8B%E6%A8%A1%E5%9E%8B%E8%88%87%E8%A8%93%E7%B7%B4.html">(三)建置模型並訓練</a>所使用資料來源。</p>

<p>關於一些必要參數配置，可在<code class="language-plaintext highlighter-rouge">Config.py</code> 裡面找到，如需改請找到對應參數進行修改。</p>

<p>使用Tensorflow官方<a href="https://www.tensorflow.org/tutorials/sequences/audio_recognition">Simple Audio Recognition</a>例子內所使用之語音資料。</p>

<p>語音資料來源：<a href="https://storage.cloud.google.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz">https://storage.cloud.google.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz</a></p>

<p>語音資料內容為收集眾多不同人對於單字詞，進行口說錄音語音檔案(wav)，每一個音檔時間為一秒，共有35個分類(每一類為一個資料夾)。</p>

<p><code class="language-plaintext highlighter-rouge">Config.py</code>內一些參數如下：</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">data_quantity_max</code>–&gt; 此參數主要管控要對一個類別產生多少個語音特徵文字檔。
    <ul>
      <li>例如：data_quantity_max ＝ 450
        <ul>
          <li>代表每一個類別要產生450個語音特徵文字檔，總共會產生15750個語音特徵文字檔。</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">sample_rate</code> –&gt; 語音之頻率參數。</li>
  <li><code class="language-plaintext highlighter-rouge">max_pad_len</code>，語音特徵向量內每一個位置長度。</li>
  <li><code class="language-plaintext highlighter-rouge">channel</code> –&gt; single channel。</li>
  <li><code class="language-plaintext highlighter-rouge">Audio_Data_Directory_Root</code> –&gt; 音頻檔案目錄所在位置。</li>
  <li><code class="language-plaintext highlighter-rouge">Audio_Data_DirectoryName</code> –&gt; 音頻檔案目錄名稱</li>
  <li><code class="language-plaintext highlighter-rouge">Log_DirectoryName</code> –&gt; 擷取出來相關檔案放置位置。</li>
  <li><code class="language-plaintext highlighter-rouge">log_file_type</code> –&gt; 檔案類型，預設使用txt。</li>
  <li><code class="language-plaintext highlighter-rouge">Log_FeatureData_DirectoryName</code> –&gt; 放置所有特徵檔案目錄名稱。</li>
  <li><code class="language-plaintext highlighter-rouge">Log_ClassLabelsData_DirectoryName</code> –&gt; 放置分類對應表檔案目錄名稱。</li>
</ul>

<p>內部針對語音特徵擷取之處理，實際是在<code class="language-plaintext highlighter-rouge">Load_Data.py</code>進行，使用Python Package — librosa 進行 MFCC 特徵擷取</p>

<p>有關 librosa 資訊可參考：</p>
<ul>
  <li><a href="https://github.com/librosa/librosa">https://github.com/librosa/librosa</a></li>
  <li><a href="https://blog.manash.me/building-a-dead-simple-word-recognition-engine-using-convnet-in-keras-25e72c19c12b">https://blog.manash.me/building-a-dead-simple-word-recognition-engine-using-convnet-in-keras-25e72c19c12b</a></li>
  <li><a href="https://ithelp.ithome.com.tw/articles/10195763">https://ithelp.ithome.com.tw/articles/10195763</a></li>
</ul>

<p>關於 MFCC 特徵值如何取得，使用 librosa 內 librosa.core.load()方法進行讀取語音檔案，給予必要2個參數分別是<strong>path</strong>(語音檔案來源)與<strong>sr</strong>(採樣頻率)。</p>

<p><strong>path</strong>會在程式中自動抓取判斷，sr是對應在<code class="language-plaintext highlighter-rouge">Config.py</code>內<code class="language-plaintext highlighter-rouge">sample_rate</code>參數配置，預設為16000。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">wave</span><span class="p">,</span> <span class="n">sr</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">mono</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sample_rate</span><span class="p">)</span>
</code></pre></div></div>

<p>將讀取語音內容進行長度裁切處理，從0索引位置開始，每隔3個位置取出一次內容，也就是內容總長度/3。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">wave</span> <span class="o">=</span> <span class="n">wave</span><span class="p">[::</span><span class="mi">3</span><span class="p">]</span>
</code></pre></div></div>

<p>使用 librosa 內 librosa.feature.mfcc ()方法進行MFCC特徵值擷取，給予必要2個參數分別是<code class="language-plaintext highlighter-rouge">wave</code>(語音檔案內容)與<code class="language-plaintext highlighter-rouge">sr</code>(採樣頻率)。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mfcc</span> <span class="o">=</span> <span class="n">librosa</span><span class="p">.</span><span class="n">feature</span><span class="p">.</span><span class="n">mfcc</span><span class="p">(</span><span class="n">wave</span><span class="p">,</span> <span class="n">sr</span><span class="o">=</span><span class="n">sample_rate</span><span class="p">)</span>
</code></pre></div></div>

<hr />

<h2 id="開始執行語音特徵資料擷取">開始執行語音特徵資料擷取</h2>

<p>主要執行程式： <code class="language-plaintext highlighter-rouge">Gen_Datafile.py</code></p>

<p>如果要更動來源位置或目錄名稱，請更改在<code class="language-plaintext highlighter-rouge">Config.py</code>內以下參數值</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">Audio_Data_Directory_Root</code></li>
  <li><code class="language-plaintext highlighter-rouge">Audio_Data_DirectoryName</code></li>
</ul>

<p>執行前需注意一點，確認是否已切入至python虛擬環境，如已切入至該虛擬環境內，在執行python3程式時，可以直接以python指令進行，因為在建立虛擬環境時，是以python3版本進行環境建置，python指令會直接指向python3。</p>

<p>在終端機打以下指令，執行<code class="language-plaintext highlighter-rouge">Gen_Datafile.py</code></p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python Gen_Datafile.py
</code></pre></div></div>

<p><img src="edgetpu02-01.png" class="img-fluid rounded mx-auto" />
<img src="edgetpu02-02.png" class="img-fluid rounded mx-auto" /></p>

<p>執行結果會根據在<code class="language-plaintext highlighter-rouge">Config.py</code>以下參數設置</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">Log_DirectoryName</code></li>
  <li><code class="language-plaintext highlighter-rouge">Log_FeatureData_DirectoryName</code></li>
  <li><code class="language-plaintext highlighter-rouge">Log_ClassLabelsData_DirectoryName</code></li>
</ul>

<p>預設在專案目錄內<code class="language-plaintext highlighter-rouge">log_file/</code>，放置處理後兩個結果，分別放置目錄名稱如下：</p>

<ol>
  <li>
    <p><code class="language-plaintext highlighter-rouge">log_file/audio_feature</code> 資料目錄</p>

    <p>放置 35 個類別各自 450 個語音特徵文字檔，每一筆語音特徵結構為(20,11)，也就是每一個語音會產生 20 列特徵值，並且每一筆特徵長度會是 11 欄。</p>

    <p><img src="edgetpu02-03.png" class="img-fluid rounded mx-auto" /></p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">log_file/audio_classlabels</code> 資料目錄</p>

    <p><code class="language-plaintext highlighter-rouge">audio_classlabels.txt</code>放置每一個分類之編號文字檔，編號從0開始，也就是35個類別範圍在0~34，此編號用在預測識別結果查詢上。</p>

    <p><img src="edgetpu02-04.png" class="img-fluid rounded mx-auto" /></p>
  </li>
</ol>

<p>到目前階段為止，針對語音特徵資料之處理，我們已產生各類別自己450個語音特徵文字檔與放置各類別所屬編號<code class="language-plaintext highlighter-rouge">audio_classlabels.txt</code>檔案。</p>

<hr />



    <script src="https://utteranc.es/client.js" repo="s123600g/s123600g.github.io"
      issue-term="title" theme="boxy-light"
      label="Article" crossorigin="anonymous" async></script>
  </main>
</body>

<div class="container">
    <footer class="d-flex flex-wrap justify-content-between align-items-center py-3 my-4 border-top">
        <div class="col-md-4 d-flex align-items-center">
            <a href="/" class="mb-3 me-2 mb-md-0 text-muted text-decoration-none lh-1">
                <svg class="bi" width="30" height="24">
                    <use xlink:href="#bootstrap"></use>
                </svg>
            </a>
            <span class="text-muted">© 2023 JYUN YU LI. All rights reserved.</span>
        </div>

        <ul class="nav col-md-4 justify-content-end list-unstyled d-flex">
            <li class="ms-3">
                <a class="text-muted" href="https://github.com/s123600g" target="_blank">
                    <i class="fab fa-github fs-3"></i>
                </a>
            </li>

            <li class="ms-3">
                <a class="text-muted" href="mailto://s123600g@gmail.com">
                    <i class="fas fa-envelope fs-3"></i>
                </a>
            </li>
        </ul>
    </footer>
</div>

</html>